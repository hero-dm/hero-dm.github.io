<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Human feedback-efficient reinforcement learning for online diffusion model finetuning">
  <meta name="keywords" content="HERO">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HERO: Human-Feedback-Efficient Reinforcement Learning for Online Diffusion Model Finetuning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="static/images/hero-icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>


<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">HERO: <u>H</u>uman-Feedback-<u>E</u>fficient <u>R</u>einforcement Learning for <u>O</u>nline Diffusion Model Finetuning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://misoshiruseijin.github.io/">Ayano Hiranaka</a><sup>*♨1,3</sup>,</span>
            <span class="author-block">
              <a href="https://shangfuchen.github.io/">Shang-Fu Chen</a><sup>*♨1,2</sup>,</span>
            <span class="author-block">
              <a href="https://chiehhsinjesselai.github.io/">Chieh-Hsin Lai</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/dongjun-kim">Dongjun Kim</a><sup>4</sup>,</span>
            <span class="author-block">
              <span class="author-color">Naoki Murata</span><sup>1</sup>,</span>
            <span class="author-block">
              <span class="author-color">Takashi Shibuya</span><sup>1</sup>,</span>
            <span class="author-block">
              <span class="author-color">Wei-Hsiang Liao</span><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://shaohua0116.github.io/">Shao-Hua Sun</a><sup>†2</sup>,</span>
            <span class="author-block">
              <a href="https://www.yukimitsufuji.com/">Yuki Mitsufuji</a><sup>†1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Sony AI,</span>
            <span class="author-block"><sup>2</sup>Graduate Institute of Communication Engineering, National Taiwan University</span>
            <span class="author-block"><sup>3</sup>University of Southern California,</span>
            <span class="author-block"><sup>4</sup>Stanford University</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><span class="hero-color"><b>ICLR 2025</b></span></span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution (Randomly Ordered)</span>
            <span class="author-block"><sup>†</sup>Equal Advising</span>
          </div>
        
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>♨</sup>Internship at Sony AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=yMHe9SRvxk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2410.05116"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/sony/hero/" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon!)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/hero-pullfigure.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        HERO efficiently fintetunes text-to-image diffusion models with minimal online human feedback (&lt;1K) for various tasks.
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Controllable generation through Stable Diffusion (SD) fine-tuning aims to improve fidelity, safety, and alignment 
            with human guidance. 
            Existing reinforcement learning from human feedback methods usually rely on 
            predefined heuristic reward functions or pretrained reward models built on large-scale datasets, 
            limiting their applicability to scenarios where collecting such data is costly or difficult.
          </p>
          <p>
            To effectively and efficiently utilize human feedback, we develop a framework,
            <b>HERO (Human-Feedback-Efficient Reinforcement Learning for Online Diffusion Model Finetuning)</b>, 
            which leverages online human feedback collected on the fly during model learning. 
            Specifically, HERO features two key mechanisms: 
            <span class="hero-color"><b>(1)</b> <b>Feedback-Aligned Representation Learning</b></span>, 
            an online training method that captures human feedback and provides informative learning signals for diffusion model finetuning, 
            and <span class="hero-color"><b>(2)</b> <b>Feedback-Guided Image Generation</b></span>, which involve generating images from SD's refined initialization samples, 
            enabling faster convergence towards the evaluator's intent.
          </p>
          <p>
            We demonstrate that HERO is 4x more efficient in online feedback for body part anomaly correction 
            compared to the best existing method. 
            Additionally, experiments show that HERO can effectively handle tasks like 
            reasoning, counting, personalization, and reducing NSFW content with only 0.5K online feedback.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Method Overview -->
      <div class="column">
        <h2 class="title is-3">HERO Framework</h2>
        <div class="columns is-centered">
          <div class="column content">
            <video id="overview-video" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/hero-pipeline.mp4"
                      type="video/mp4">
            </video>
            <p>
              HERO finetunes the Stable Diffusion model in the following steps:
            </p>
            <p>
              <span class="hero-color"><b>Image generation:</b></span> A batch of images are sampled from the Stable Diffusion model.
            </p>
            <p>
              <span class="hero-color"><b>Human feedback:</b></span> Human evaluator provides binary feedback ("good"/"bad") for each image, 
              and chooses one "best" image among the "good" images.
            </p>
            <p>
              <span class="hero-color"><b>Feedback-aligned representation learning:</b></span> Human annotations are used to train
              an embedding map, which encodes images into continuous representations that reflect human evaluations.
            </p>
            <p>
              <span class="hero-color"><b>Similarity-based reward computation:</b></span> Each image is assigned a score based on
              their cosine similarities to the "best" image in the learned feedback-aligned representation space.
            </p>
            <p>
              <span class="hero-color"><b>Diffusion model finetuning:</b></span> Stable Diffusion model is funetuned via DDPO using
              the computed scores as rewards.
            </p>
            <p>
              <span class="hero-color"><b>Feedback-guided image generation:</b></span> The next batch of images are sampled from a
              Gaussian mixture of noises that generated the "good" images in the previous iteration.
            </p>
          </div>

        </div>
      </div>
    </div>
    <!--/ Method Overview -->

    <!-- Tasks -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Variety of Tasks</h2>
        <div class="content has-text-justified">
          <p>
            HERO can address a variety of tasks, 
            including hand deformation correction, content safety improvement, reasoning, and personalization.
          </p>
          <img src="static/images/before-after-superclass.png">
        </div>
        <h3 class="title is-4">Quantitative Results</h3>
        <div class="content has-text-justified">
          <p>
            <b>HERO achieves highest success rates in all tasks.</b>
            In a hand anomaly correction task, we further compare HERO's sample efficiency to a prior work, 
            demonstrating that 
            <b>HERO is 4x more sample-efficient in terms of human feedback.</b>
          </p>
          <img src="static/images/quantitative_results.png">
        </div>
        <br/>
      </div>
    </div>
    <!--/ Tasks -->

    <!-- Transferability -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Transferability to Unseen Prompts</h2>
        <div class="content has-text-justified"></div>
          <p>
            HERO demonstrates transferability to previously unseen inference prompts, 
            showcasing that the desired concepts were acquired by the model.
          </p>
        <br/>

        <h3 class="title is-4">Personal Preference Transfer</h2>
        <div class="content has-text-justified">
          <img src="static/images/transfer_mountain_v3-min.png">
          <p>
            Models trained with two distinct personal preferences (<i>green</i> vs <i>snowy</i>) generated
            images that inherit these preferences when prompted with a related, unseen task.
          </p>
        </div>

        <h3 class="title is-4">Content Safety Transfer</h2>
          <div class="content has-text-justified">
            <p>
              HERO model is trained using the prompt <i>"sexy"</i> to reduce nudity. When prompted with 
              potentially NSFW prompts, HERO-trained model shows significantly higher content safety rate
              of 87.0%, compared to 57.5% safety rate in images generated by the pretrained Stable Diffusion model.
            </p>
            <img src="static/images/transfer_safety_hidden_v2-min.png">
            <p>
              Sample images generated by HERO model trained to improve content safety.
            </p>
          </div>
      </div>
    </div>
    <!--/ Transferability -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hiranaka2024humanfeedbackefficientreinforcementlearning,
      title={HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning}, 
      author={Ayano Hiranaka and Shang-Fu Chen and Chieh-Hsin Lai and Dongjun Kim and Naoki Murata and Takashi Shibuya and Wei-Hsiang Liao and Shao-Hua Sun and Yuki Mitsufuji},
      year={2024},
      eprint={2410.05116},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.05116}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2410.05116">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="TODO" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is built using 
            <a href="https://nerfies.github.io/">Nerfies</a>  
            project page source code,
            licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <!-- <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
